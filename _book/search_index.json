[
["regularized-regression.html", "Chapter 2 Regularized Regression check distribution after normalization 2.1 Traning model 2.2 Strengths &amp; Weaknesses", " Chapter 2 Regularized Regression 資料處理 載入wine.csv資料，並切分成訓練資料及測試資料 wine &lt;- read.csv(&quot;~/Dropbox/M-Team/ML/wine.csv&quot;) set.seed(1234) # so that the indices will be the same when re-run trainIndices = createDataPartition(wine$quality, p=.8, list=F) wine_train = wine %&gt;% select(-free.sulfur.dioxide, -density, -color, -white) %&gt;% slice(trainIndices) wine_test = wine %&gt;% select(-free.sulfur.dioxide, -density, -color, -white) %&gt;% slice(-trainIndices) check distribution after normalization Pre-processing setup The preprocess method here is: \\[\\frac{x_i-min}{max-min}\\] it looks like alcohol content and volatile acidity separate most with regard to the ‘good’ class. wine_trainplot = select(wine_train, -quality) %&gt;% preProcess(method=&#39;range&#39;) %&gt;% #標準化處理range =&gt; (x-min)/(max-min) predict(newdata= select(wine_train, -quality)) #利用predict函數顯示出處理好的矩陣 featurePlot(wine_trainplot, wine_train$quality, &#39;box&#39;) 2.1 Traning model (Tuning) parameter set setup The function “expand.grid”, will create a grid of that number of values for each tuning parameter. alpha = mixing percentage, If we set the alpha to 1, it will present a standard lasso penalty, and 0 would be the ridge penalty. lambda = This parameter can control the penalty amount. # cross validation 10 cv_opts = trainControl(method=&#39;cv&#39;, number=10) #定義模型訓練參數，劃分十組交叉驗證（使用repeatedcv可重複劃分） regreg_opts = expand.grid(.alpha = seq(.1, 1, length = 5), .lambda = seq(.1, .5, length = 5)) #25種組合(決定lamda重要度？) results_regreg = train(quality~., data=wine_train, method = &quot;glmnet&quot;, trControl = cv_opts, preProcess = c(&quot;center&quot;, &quot;scale&quot;), #指定數據標準化，&quot;center&quot;和&quot;scale&quot;。其中center表示預測變量減去均值 tuneGrid = regreg_opts) results_regreg #kappa是一統計量指標衡量預測值與實質的差距 ## glmnet ## ## 5199 samples ## 10 predictor ## 2 classes: &#39;bad&#39;, &#39;good&#39; ## ## Pre-processing: centered (10), scaled (10) ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 4679, 4680, 4679, 4679, 4679, 4679, ... ## Resampling results across tuning parameters: ## ## alpha lambda Accuracy Kappa ## 0.100 0.1 0.7255274 0.35008588 ## 0.100 0.2 0.6949431 0.24105753 ## 0.100 0.3 0.6730163 0.15106604 ## 0.100 0.4 0.6516660 0.07063484 ## 0.100 0.5 0.6364689 0.01492729 ## 0.325 0.1 0.7139856 0.31350196 ## 0.325 0.2 0.6703273 0.13726298 ## 0.325 0.3 0.6330066 0.00000000 ## 0.325 0.4 0.6330066 0.00000000 ## 0.325 0.5 0.6330066 0.00000000 ## 0.550 0.1 0.7043676 0.27703468 ## 0.550 0.2 0.6330066 0.00000000 ## 0.550 0.3 0.6330066 0.00000000 ## 0.550 0.4 0.6330066 0.00000000 ## 0.550 0.5 0.6330066 0.00000000 ## 0.775 0.1 0.6882142 0.21713151 ## 0.775 0.2 0.6330066 0.00000000 ## 0.775 0.3 0.6330066 0.00000000 ## 0.775 0.4 0.6330066 0.00000000 ## 0.775 0.5 0.6330066 0.00000000 ## 1.000 0.1 0.6630178 0.11541687 ## 1.000 0.2 0.6330066 0.00000000 ## 1.000 0.3 0.6330066 0.00000000 ## 1.000 0.4 0.6330066 0.00000000 ## 1.000 0.5 0.6330066 0.00000000 ## ## Accuracy was used to select the optimal model using the largest value. ## The final values used for the model were alpha = 0.1 and lambda = 0.1. ggplot(results_regreg) preds_regreg = predict(results_regreg, wine_test) good_observed = wine_test$quality confusionMatrix(preds_regreg, good_observed, positive=&#39;good&#39;) ## Confusion Matrix and Statistics ## ## Reference ## Prediction bad good ## bad 197 76 ## good 279 746 ## ## Accuracy : 0.7265 ## 95% CI : (0.7014, 0.7506) ## No Information Rate : 0.6333 ## P-Value [Acc &gt; NIR] : 6.665e-13 ## ## Kappa : 0.3531 ## Mcnemar&#39;s Test P-Value : &lt; 2.2e-16 ## ## Sensitivity : 0.9075 ## Specificity : 0.4139 ## Pos Pred Value : 0.7278 ## Neg Pred Value : 0.7216 ## Prevalence : 0.6333 ## Detection Rate : 0.5747 ## Detection Prevalence : 0.7897 ## Balanced Accuracy : 0.6607 ## ## &#39;Positive&#39; Class : good ## The lower bound (and p-value) suggests we are statistically predicting better than the No Information Rate (i.e., just guessing the more prevalent ‘Bad’ category) -&gt; 猜好的比猜壞的還強 What is “kappa”? What is “McNemar’s test”? confusionMatrix(preds_regreg, good_observed, positive=&#39;good&#39;, mode=&#39;prec_recall&#39;) ## Confusion Matrix and Statistics ## ## Reference ## Prediction bad good ## bad 197 76 ## good 279 746 ## ## Accuracy : 0.7265 ## 95% CI : (0.7014, 0.7506) ## No Information Rate : 0.6333 ## P-Value [Acc &gt; NIR] : 6.665e-13 ## ## Kappa : 0.3531 ## Mcnemar&#39;s Test P-Value : &lt; 2.2e-16 ## ## Precision : 0.7278 ## Recall : 0.9075 ## F1 : 0.8078 ## Prevalence : 0.6333 ## Detection Rate : 0.5747 ## Detection Prevalence : 0.7897 ## Balanced Accuracy : 0.6607 ## ## &#39;Positive&#39; Class : good ## 2.2 Strengths &amp; Weaknesses Strengths 熟悉 standard/logistic regression好用常用 Weaknesses 不會自動找出相互影響的變數，或是非線性相關的回歸問題，在其他預測上就不太好用。 變數需要被縮放，不然取值範圍相差過大會導致模型可能會更偏向於取值範圍較大的那個特徵。 預測因子可能彼此相關。 "]
]
