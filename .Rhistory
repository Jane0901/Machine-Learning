library(gplots)
install.packages("gplots")
library(gplots)
library(caret)
library(tidyverse)
wine <- read.csv('~/Dropbox/M-team/ML/wine.csv')
set.seed(1234) # so that the indices will be the same when re-run
trainIndices = createDataPartition(wine$quality, p=.8, list=F)
wine_train = wine %>%
select(-X,-free.sulfur.dioxide, -density, -color, -white) %>%
slice(trainIndices)
wine_test = wine %>%
select(-X,-free.sulfur.dioxide, -density,  -color, -white) %>%
slice(-trainIndices)
wine_trainplot = select(wine_train, -quality) %>%
preProcess(method='range') %>%
predict(newdata= select(wine_train, -quality))
good_observed = wine_test$quality
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=5,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='Good')
library(gplots)
library(caret)
library(tidyverse)
wine <- read.csv('~/Dropbox/M-team/ML/wine.csv')
set.seed(1234) # so that the indices will be the same when re-run
trainIndices = createDataPartition(wine$quality, p=.8, list=F)
wine_train = wine %>%
select(-X,-free.sulfur.dioxide, -density, -color, -white) %>%
slice(trainIndices)
wine_test = wine %>%
select(-X,-free.sulfur.dioxide, -density,  -color, -white) %>%
slice(-trainIndices)
wine_trainplot = select(wine_train, -quality) %>%
preProcess(method='range') %>%
predict(newdata= select(wine_train, -quality))
good_observed = wine_test$quality
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=5,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='Good')
library(doParallel)
cl = makeCluster(2)
registerDoParallel(cl)
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=5,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='Good')
results_nnet
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=5,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='Good')
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=5,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
confusionMatrix(preds_nnet, good_observed, positive='good') #作者是Good，我們是寫good
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=3,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=3,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=6,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
library(doParallel)
cl = makeCluster(2)
registerDoParallel(cl)
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=6,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='good') #作者是Good，我們是寫good
#results_nnet1 = train(quality~.,
# data=wine_train,
#method='mlpWeightDecayML',
#trControl=cv_opts,
#preProcess=c('center', 'scale'),
#trace=F,
#maxit=10)
#results_nnet1
results_nnet
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=6,
preProcess=c('center', 'scale'),
trace=T,
maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='good') #作者是Good，我們是寫good
#results_nnet1 = train(quality~.,
# data=wine_train,
#method='mlpWeightDecayML',
#trControl=cv_opts,
#preProcess=c('center', 'scale'),
#trace=F,
#maxit=10)
#results_nnet1
results_nnet
results_nnet
results_nnet
View(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
results_nnet
plot_min_depth_interactions(results_rf$finalModel, k=7)
knitr::opts_chunk$set(echo = TRUE,eval=FALSE)
library(randomForestExplainer)
plot_min_depth_distribution(results_rf$finalModel)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=100)
library(doParallel)
cl = makeCluster(2)
registerDoParallel(cl)
library(gplots)
library(caret)
library(tidyverse)
wine <- read.csv('~/Dropbox/M-team/ML/wine.csv')
wine$quality=factor(wine$quality)
set.seed(1234) # so that the indices will be the same when re-run
trainIndices = createDataPartition(wine$quality, p=.8, list=F)
wine_train = wine %>%
select(-X,-free.sulfur.dioxide, -density, -color, -white) %>%
slice(trainIndices)
wine_test = wine %>%
select(-X,-free.sulfur.dioxide, -density,  -color, -white) %>%
slice(-trainIndices)
wine_trainplot = select(wine_train, -quality) %>%
preProcess(method='range') %>%
predict(newdata= select(wine_train, -quality))
good_observed = wine_test$quality
cv_opts = trainControl(method='cv', number=10) # cross-validation
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=100)
results_rf
library(randomForestExplainer)
plot_min_depth_distribution(results_rf$finalModel)
?plot_min_depth_interactions
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
knitr::opts_chunk$set(echo = FALSE)
library(reticulate)
use_python("/anaconda3/bin/python3.6", required = T)
use_condaenv("/anaconda3/envs/m-team")
source_python("../programs/學分超修.py")
library(plyr)
library(dplyr)
library(ggplot2)
library(grid)
library(gridExtra)
library(Rmisc)
library(kableExtra)
View(dfclean)
save(dfclean)
save(dfclean,學生型態資料)
save(dfclean,學生型態資料.Rda)
save(dfclean,學生型態資料.rda)
save(dfclean,"學生型態資料.rda")
save(dfclean,"學生型態資料".rda)
save(dfclean,"學生型態資料.RData")
save(dfclean,file=file = "學生型態資料.RData")
save(dfclean,file= "學生型態資料.RData")
save(dfclean,file= "學生型態資料.RData")
save(dfclean,file= "學生型態資料.RData")
save(dfclean,file= "學生型態資料.RData")
View(dfpr)
