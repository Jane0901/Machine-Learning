ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='good') #作者是Good，我們是寫good
#results_nnet1 = train(quality~.,
# data=wine_train,
#method='mlpWeightDecayML',
#trControl=cv_opts,
#preProcess=c('center', 'scale'),
#trace=F,
#maxit=10)
#results_nnet1
results_nnet
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=6,
preProcess=c('center', 'scale'),
trace=T,
maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='good') #作者是Good，我們是寫good
#results_nnet1 = train(quality~.,
# data=wine_train,
#method='mlpWeightDecayML',
#trControl=cv_opts,
#preProcess=c('center', 'scale'),
#trace=F,
#maxit=10)
#results_nnet1
results_nnet
results_nnet
results_nnet
View(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
results_nnet
cv_opts = trainControl(method='cv', number=10)
library(gplots)
library(caret)
library(tidyverse)
wine <- read.csv('~/Dropbox/M-team/ML/wine.csv')
set.seed(1234) # so that the indices will be the same when re-run
trainIndices = createDataPartition(wine$quality, p=.8, list=F)
wine_train = wine %>%
select(-X,-free.sulfur.dioxide, -density, -color, -white) %>%
slice(trainIndices)
wine_test = wine %>%
select(-X,-free.sulfur.dioxide, -density,  -color, -white) %>%
slice(-trainIndices)
wine_trainplot = select(wine_train, -quality) %>%
preProcess(method='range') %>%
predict(newdata= select(wine_train, -quality))
good_observed = wine_test$quality
library(doParallel)
cl = makeCluster(2)
registerDoParallel(cl)
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=6,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='good') #作者是Good，我們是寫good
#results_nnet1 = train(quality~.,
#data=wine_train,
#method='mlpWeightDecayML',
#trControl=cv_opts,
#preProcess=c('center', 'scale'),
#trace=F,
#maxit=10)
#results_nnet1
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=1000)
results_rf
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
results_nnet
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=6,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='good') #作者是Good，我們是寫good
#results_nnet1 = train(quality~.,
#data=wine_train,
#method='mlpWeightDecayML',
#trControl=cv_opts,
#preProcess=c('center', 'scale'),
#trace=F,
#maxit=10)
#results_nnet1
knitr::opts_chunk$set(echo = TRUE,eval=FALSE)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=1000)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=100)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=10)
results_rf
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=100)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=80)
results_rf
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=100)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=80)
results_rf
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=100)
library(doParallel)
cl = makeCluster(2)
registerDoParallel(cl)
registerDoParallel(cl)
library(gplots)
library(caret)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE,eval=FALSE)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=100)
results_rf
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
results_rf
rf_opts = data.frame(mtry=c(1:5))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=100)
results_rf
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
results_rf
rf_opts = data.frame(mtry=c(1:10))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=50)
results_rf
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
rf_opts = data.frame(mtry=c(5:10))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=50)
results_rf
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
results_rf
install.packages("randomForest")
install.packages(c("backports", "callr", "ddalpha", "httr", "jsonlite", "knitr", "markdown", "pillar", "readr", "rmarkdown"))
knitr::opts_chunk$set(echo = TRUE,eval=FALSE)
# https://arxiv.org/pdf/1501.07196
# tibble causes problem so convert wine_train to standard df.
library(ggRandomForests)
install.packages("ggRandomForests")
# https://arxiv.org/pdf/1501.07196
# tibble causes problem so convert wine_train to standard df.
library(ggRandomForests)
rf2 = rfsrc(formula = quality ~.,
data = data.frame(wine_train),
mtry = results_rf$finalModel$mtry)
gg_v = gg_variable(rf2)
gg_md = gg_minimal_depth(rf2)
# We want the top two ranked minimal depth variables only
xvar = gg_md$topvars[1:2]
plot(gg_v, xvar=xvar, panel=TRUE, partial=TRUE, alpha=.1)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=100)
library(doParallel)
cl = makeCluster(2)
registerDoParallel(cl)
library(gplots)
library(caret)
library(tidyverse)
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=100)
results_rf
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
varImp(results_rf)
library(randomForestExplainer)
install.packages("randomForestExplainer")
library(randomForestExplainer)
plot_min_depth_distribution(results_rf$finalModel)
plot_min_depth_interactions(results_rf$finalModel, k=7)
multi_imps = measure_importance(results_rf$finalModel)
plot_importance_ggpairs(multi_imps)
library(randomForestExplainer)
plot_min_depth_distribution(results_rf$finalModel)
plot_min_depth_interactions(results_rf$finalModel, k=7)
multi_imps = measure_importance(results_rf$finalModel)
plot_importance_ggpairs(multi_imps)
knitr::opts_chunk$set(echo = TRUE,eval=FALSE)
# https://arxiv.org/pdf/1501.07196
# tibble causes problem so convert wine_train to standard df.
library(ggRandomForests)
rf2 = rfsrc(formula = quality ~.,
data = data.frame(wine_train),
mtry = results_rf$finalModel$mtry)
gg_v = gg_variable(rf2)
gg_md = gg_minimal_depth(rf2)
# We want the top two ranked minimal depth variables only
xvar = gg_md$topvars[1:2]
plot(gg_v, xvar=xvar, panel=TRUE, partial=TRUE, alpha=.1)
set.seed(1234)
sample_index = sample(1:nrow(wine_test), 5)
sample_test = wine_test %>%
slice(sample_index) %>%
select(-good)
library(dplyr)
set.seed(1234)
sample_index = sample(1:nrow(wine_test), 5)
sample_test = wine_test %>%
slice(sample_index) %>%
select(-good)
knitr::opts_chunk$set(echo = TRUE,eval=FALSE)
library(dplyr)
set.seed(1234)
sample_index = sample(1:nrow(wine_test), 5)
sample_test = wine_test %>%
slice(sample_index) %>%
select(-good)
library(dplyr)
set.seed(1234)
sample_index = sample(1:nrow(wine_test), 5)
sample_test = wine_test %>%
slice(sample_index) %>%
select(-Good)
library(doParallel)
cl = makeCluster(2)
registerDoParallel(cl)
library(dplyr)
set.seed(1234)
sample_index = sample(1:nrow(wine_test), 5)
sample_test = wine_test %>%
slice(sample_index) %>%
select(-good)
library(gplots)
library(caret)
library(tidyverse)
wine <- read.csv('~/Dropbox/M-team/ML/wine.csv')
set.seed(1234) # so that the indices will be the same when re-run
trainIndices = createDataPartition(wine$quality, p=.8, list=F)
wine_train = wine %>%
select(-X,-free.sulfur.dioxide, -density, -color, -white) %>%
slice(trainIndices)
wine_test = wine %>%
select(-X,-free.sulfur.dioxide, -density,  -color, -white) %>%
slice(-trainIndices)
wine_trainplot = select(wine_train, -quality) %>%
preProcess(method='range') %>%
predict(newdata= select(wine_train, -quality))
good_observed = wine_test$quality
cv_opts = trainControl(method='cv', number=10) # cross-validation
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=5,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='good')
#results_nnet1 = train(quality~.,
# data=wine_train,
#method='mlpWeightDecayML',
#trControl=cv_opts,
#preProcess=c('center', 'scale'),
#trace=F,
#maxit=10)
#results_nnet1
results_nnet = train(quality~.,
data=wine_train,
method='avNNet',
trControl=cv_opts,
tuneLength=5,
preProcess=c('center', 'scale'),
trace=F,
maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
labs(x='Number of Hidden Units') +
scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='good')
rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~.,
data = wine_train,
method = 'rf',
preProcess = c('center', 'scale'),
trControl = cv_opts,
tuneGrid = rf_opts,
localImp = T,
ntree=100)
results_rf
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
library(randomForestExplainer)
plot_min_depth_distribution(results_rf$finalModel)
plot_min_depth_interactions(results_rf$finalModel, k=7)
multi_imps = measure_importance(results_rf$finalModel)
plot_importance_ggpairs(multi_imps)
library(randomForestExplainer)
plot_min_depth_distribution(results_rf$finalModel)
plot_min_depth_interactions(results_rf$finalModel, k=7)
library(dplyr)
set.seed(1234)
sample_index = sample(1:nrow(wine_test), 5)
sample_test = wine_test %>%
slice(sample_index) %>%
select(-good)
# https://arxiv.org/pdf/1501.07196
# tibble causes problem so convert wine_train to standard df.
library(ggRandomForests)
rf2 = rfsrc(formula = quality ~.,
data = data.frame(wine_train),
mtry = results_rf$finalModel$mtry)
gg_v = gg_variable(rf2)
gg_md = gg_minimal_depth(rf2)
# We want the top two ranked minimal depth variables only
xvar = gg_md$topvars[1:2]
plot(gg_v, xvar=xvar, panel=TRUE, partial=TRUE, alpha=.1)
library(dplyr)
set.seed(1234)
sample_index = sample(1:nrow(wine_test), 5)
sample_test = wine_test %>%
slice(sample_index) %>%
select(-good)
wine_test
library(dplyr)
set.seed(1234)
sample_index = sample(1:nrow(wine_test), 5)
sample_test = wine_test %>%
slice(sample_index) %>%
select(-quality)
library(lime)
install.packages("lime")
library(dplyr)
set.seed(1234)
sample_index = sample(1:nrow(wine_test), 5)
sample_test = wine_test %>%
slice(sample_index) %>%
select(-quality)
library(lime)
rf_lime = lime(wine_train, results_rf)
rf_explain = explain(sample_test,
rf_lime,
n_features = 3,
feature_select = 'highest_weights',
labels = 'Good')
