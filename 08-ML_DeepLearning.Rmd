# (PART) Part II: Unsupervised-Learning{-}

# Basic Understanding

> 這個章節想要回答的是，非監督式學習他能幫助我們解決什麼問題？常見的使用場合是？

其目的是去對原始資料進行分類，以便了解資料內部結構。有別於監督式學習網絡，無監督式學習網絡在學習時並不知道其分類結果是否正確，亦即沒有受到監督式增強(告訴它何種學習是正確的)。其特點是僅對此種網絡提供輸入範例。而它會自己主動從這些範例中找出其潛在類別規則。當學習完成並經測試後，也能夠將之應用到新的案例上。

* 監督式學習：資料已有標記，運用已標記資料來做訓練，所以模型評估講求準度。
* 非監督式學習：資料沒有標記，從中找出擁有相同特徵的資料群，所以是找出資料間大致分布的趨勢，而沒有要預測的對象。

## Cluster{-}

分群是一種將資料分類成群的方法，為一種非監督式學習，也就是訓練資料沒有預先定義的標籤。其主要的目的在於找出資料中相似的幾個群聚，讓在同一個子集中的成員對象都有相似的一些屬性，常見的包括在坐標系中更加短的空間距離等。

一般而言，分群法可以大致歸為兩大類：

* 階層式分群法 (hierarchical clustering) : 群的數目可以由大變小(divisive hierarchical clustering)，或是由小變大(agglomerative hierarchical clustering)，來進群聚的合併或分裂，最後再選取最佳的群的數目。

* 分割式分群法 (partitional clustering) : 先指定群的數目後，再用一套疊代的數學運算法，找出最佳的分群方式以及相關的群中心。

常見的分法有K-平均演算法、階層式分群、混合模型。

### K-平均演算法{-}

參考資料：

- [K平均演算法 Clustering: K-means Algorithm](http://mropengate.blogspot.com/2015/06/ai-ch16-5-k-introduction-to-clustering.html)

- [https://zh.wikipedia.org/wiki/K-平均算法](https://zh.wikipedia.org/wiki/K-%E5%B9%B3%E5%9D%87%E7%AE%97%E6%B3%95)

#### 概念{-}

把n個點劃分到k個聚類中，使得每個點都屬於離他最近的均值(聚類中心)對應的聚類，以之作為聚類的標準。

這個問題在計算上是 [NP困難](https://zh.wikipedia.org/wiki/NP%E5%9B%B0%E9%9A%BE)，不過存在高效的 [啟發式演算法](https://zh.wikipedia.org/wiki/%E5%90%AF%E5%8F%91%E5%BC%8F%E6%90%9C%E7%B4%A2)。一般情況下，都使用效率比較高的啟發式演算法，它們能夠快速收斂於一個局部最優解。

這些演算法通常類似於通過疊代最佳化方法處理高斯混合分布的最大期望演算法（EM演算法）。而且，它們都使用聚類中心來為資料建模；然而k-平均聚類傾向於在可比較的空間範圍內尋找聚類，期望-最大化技術卻允許聚類有不同的形狀。

>聚類數目k是一個輸入參數，通常要進行特徵檢查以決定聚類數目。

#### 演算法描述{-}

已知觀測集(x1,x2,...,xn)，其中每個觀測都是一個d-維實向量，k-平均聚類要把這n個觀測劃分到k個集合中(k≤n),使得組內平方和（WCSS within-cluster sum of squares）最小。

Min WCSS : $\sum\ ^k _{i=1} \sum\ _{x\in S _i} \|x-\mu_i \|^2$

步驟一：分配(Assignment)

將每個觀測分配到聚類中，使組內平方和(WCSS)達最小。因為這一平方和就是平方後的歐氏距離，所以很直觀地把觀測分配到離它最近得均值點即可。

步驟二：更新(Update)

計算上步得到聚類中每一聚類觀測值圖心，作為新均值點。

交替進行的兩個步驟都會減小目標函式的值，並且分配方案只有有限種，所以演算法一定會收斂於某一（局部）最優解。

#### 優缺點{-}

* 優點：

1. 簡單好理解。
2. 項目自動分配給群集。

* 缺點：

1. 收斂到局部最佳解，而不是整體最佳解。
1. 聚類數目k是一個輸入參數，選擇不恰當的k值可能會導致糟糕的聚類結果，所以必須先預測集群數量（要檢查特徵）。
3. 所有項目強制列入群集。
4. 對極端值很敏感，但可用K-medians(中位數)、K-medoids(用真實資料點而非不一定存在的群集中心點）替代解決。

## Latent Variable Models{-}

[Thinking about Latent Variables by Michael Clark](https://m-clark.github.io/sem/FA_notes.html)

Latent Variable是一個很大的主題。多半是和降維有關，我如何用較少的變數來捕捉我想要觀察的東西，而且那個東西有時並不直觀，很多外顯的東西（indicator
，指標或者訊號）能夠代表他，但始終無法代表他的全部。

舉例來說，你如何衡量一個人有多快樂？快樂指數即可理解為一個latent variable

- 他們是否在笑

- 他們跟他人互動的情況如何

<div style="color:tomato;">latent variable，經濟學上叫做什麼？</div>

### 常見的分析手法{-}

- PCA 主成份分析

- Factor Analysis

#### 背後關鍵的處理原則{-}

- Dimension Reduction/Data compression : 我如何盡可能用較少的變數以及觀測值並保持住我所想要資料特性

- Matrix Factorization: 我如何將一個大的矩陣，拆解成許多的小矩陣。

- Latent Linear Models: 藉此彌補一個基本常用的Multi-OLS的不足。

- Measurement error: <div style="color:tomato;">我不太理解什麼是Measurement error</div>

#### PCA示範{-}

> we seek to find orthogonal (i.e. uncorrelated) factors to maximize the variance accounted for by each factor. [with a good link](https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8-%E7%B5%B1%E8%A8%88%E5%AD%B8%E7%BF%92-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-principle-component-analysis-pca-58229cd26e71)

```{r}
#Agreeableness
#Conscientiousness
#Openness to experience
#Extraversion
#Neuroticism
library(psych)
bfi_trim = bfi %>% 
  select(matches('A[1-5]|N[1-5]'))
#Agreeableness and Neuroticism items were chosen 
```

<div style="color:tomato;">我不太理解什麼是h2, com</div>

```{r}
pc = principal(bfi_trim, 2)
```

```{r}
pc
```



## Graphical Structure{-}

非監督式學習用意是在找尋資料本身的大致的趨勢（pattern）或架構（structure），有些手法能夠用視覺化的方式（e.g.network analysis）來看到樣本間的關聯，包含誰跟誰較為相近等。

進一步可以參考：[Graphical & Latent Variable Modeling by Michael clark](https://m-clark.github.io/sem/)

## Imputation{-}

當資料本身有缺失值的時候，也可以用非監督式學習的方式來計算推論可能的值。

舉例來說，推薦系統即是用既有的用戶資料，以及與該用戶相近的其他使用者的購買狀況進行推論它可能會喜歡什麼。

## Ensembles{-}

我如何透過幾個可能的手法，來提升我的準確度

- Bagging：針對樣本

- Boosting：針對單一個模型

- Stacking：如何將不同的模型結合起來

<div style="color:tomato;">這跟非監督式學習還有關係嗎？</div>

### Bagging{-}

Bagging基本上就是bootstrap aggregation。我透過不斷重新抽樣本並丟入模型，最終取所有樣本的預測表現之平均。藉此可以在不影響偏誤（bias）下，降低我預測結果的變異程度（variance）。

至少我不會一次丟到靶心，下一次卻什麼也沒射中。


### Boosting{-}

#### R Code Example{-}

```{r}
#The following object is masked from ‘package:dplyr’:slice
#be aware the same slice function from two different package
    
library(xgboost)
modelLookup("xgbLinear")
modelLookup("xgbTree")
```

```{r}
xgb_opts = expand.grid(eta=c(.3,.4),
                       max_depth=c(9, 12),
                       colsample_bytree=c(.6,.8),
                       subsample=c(.5,.75,1),
                       nrounds=1000,
                       min_child_weight=1,
                       gamma=0)
```

```{r}
set.seed(1234)
#the R code form m-clark has the object called 'good'. Be aware the variable name is different or not, and the technique are all the same
results_xgb = train(quality~.,  
                    data=wine_train, 
                    method='xgbTree',
                    preProcess=c('center', 'scale'), 
                    trControl=cv_opts, 
                    tuneGrid=xgb_opts)
results_xgb
preds_gb = predict(results_xgb, wine_test)
confusionMatrix(preds_gb, good_observed, positive='Good')
```


### Stacking{-}

也許我嘗試了幾個模型，準確度各有千秋不至於落差太多，我如何結合他們，發揮1+1>2的效果？

一種方式是跟bagging的想法相同。不同模型下去跑，並且取平均。另外一種方式是以準確度較高的模型，給予他較高的權重。

另外一種方式是利用各個模型在test set的表現，去找到最適合的一個data set並且去訓練 meta-learner model. 

<div style="color:tomato;">我不太理解什麼是meta-learner</div>

