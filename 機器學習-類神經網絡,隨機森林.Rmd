```{r}
library(doParallel)
cl = makeCluster(2)
registerDoParallel(cl)
library(gplots)
library(caret)
library(tidyverse)
wine <- read.csv('~/Dropbox/M-team/ML/wine.csv')
set.seed(1234) # so that the indices will be the same when re-run
trainIndices = createDataPartition(wine$quality, p=.8, list=F)

wine_train = wine %>% 
  select(-X,-free.sulfur.dioxide, -density, -color, -white) %>% 
  slice(trainIndices)

wine_test = wine %>% 
  select(-X,-free.sulfur.dioxide, -density,  -color, -white) %>% 
  slice(-trainIndices)

wine_trainplot = select(wine_train, -quality) %>% 
  preProcess(method='range') %>% 
  predict(newdata= select(wine_train, -quality))

good_observed = wine_test$quality

```


類神經網絡：

```{r}
cv_opts = trainControl(method='cv', number=10)
results_nnet = train(quality~., 
                     data=wine_train, 
                     method='avNNet',
                     trControl=cv_opts,
                     tuneLength=5,
                     preProcess=c('center', 'scale'),
                     trace=F, 
                     maxit=10)
results_nnet
ggplot(results_nnet)
ggplot(results_nnet) +
  labs(x='Number of Hidden Units') +
  scale_x_continuous(breaks = c(1,3,5,7,9))
preds_nnet = predict(results_nnet, wine_test)
confusionMatrix(preds_nnet, good_observed, positive='good')


#results_nnet1 = train(quality~., 
                    # data=wine_train, 
                     #method='mlpWeightDecayML',
                     #trControl=cv_opts,
                     #preProcess=c('center', 'scale'),
                     #trace=F, 
                     #maxit=10)
#results_nnet1

```

隨機森林：

```{r}

rf_opts = data.frame(mtry=c(2:6))
results_rf = train(quality~., 
                   data = wine_train,
                   method = 'rf',
                   preProcess = c('center', 'scale'),
                   trControl = cv_opts,
                   tuneGrid = rf_opts,
                   localImp = T,
                   ntree=1000)
results_rf
preds_rf = predict(results_rf, wine_test)
preds_rf
confusionMatrix(preds_rf, good_observed, positive='good')
varImp(results_rf)
```

```{r}
library(randomForestExplainer)
plot_min_depth_distribution(results_rf$finalModel)
plot_min_depth_interactions(results_rf$finalModel, k=7)

multi_imps = measure_importance(results_rf$finalModel)
plot_importance_ggpairs(multi_imps)

```

```{r}
# https://arxiv.org/pdf/1501.07196
# tibble causes problem so convert wine_train to standard df.
library(ggRandomForests)
rf2 = rfsrc(formula = quality ~., 
            data = data.frame(wine_train),
            mtry = results_rf$finalModel$mtry)
gg_v = gg_variable(rf2)
gg_md = gg_minimal_depth(rf2)

# We want the top two ranked minimal depth variables only
xvar = gg_md$topvars[1:2]
plot(gg_v, xvar=xvar, panel=TRUE, partial=TRUE, alpha=.1)
```


